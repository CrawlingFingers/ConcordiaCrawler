
<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html>
  <head>
    <title>Syllabus for COMP-598 Topics in Computer Science: Applied Machine Learning (Fall 2014)</title>
  </head>

<!-- Background white, text black, links blue (unvisited), navy (visited), red (active) -->
 <BODY
  BGCOLOR="#FFFFFF"
  TEXT="#000000"
  LINK="#0000FF"
  VLINK="#0000A0"
 >
<font FACE="geneva,arial,helvetica">
<center>    <h2>COMP-598 Topics in Computer Science: Applied Machine Learning</h2></center>
<center>    <h2>Syllabus - Fall 2014</h2></center>

<hr>

<p><h3><u>General Information</u></h3>

<center><table BORDER=0 CELLSPACING=1 CELLPADDING=2 WIDTH="95%" NOSAVE >

<tr>
<td><u>Location:</u></td><td>Trottier, ENGTR 2120</td>
</tr>

<tr>
<td><u>Times:</u></td><td>Tuesday / Thursday, 11:30am-1:00pm</td>
</tr>

<tr>
<td><u>Instructor:</u><br>&nbsp;<br>&nbsp;</td>
<td><b>Prof. Joelle Pineau</b>, School of Computer Science<br>
Email: <i>jpineau@cs.mcgill.ca</i> <br>
Office: McConnell 106N<br>
Office hours: Thursday, 1:00-2:30pm</td>
</tr>

<tr>
<td><u>Teaching assistants:</u><br>&nbsp;<br>&nbsp;</td>
<td><b>Pierre-Luc Bacon</b><br>
Email: <i>pbacon@cs.mcgill.ca</i><br>
Office: McConnell 111<br>
Office hours: Wednesday, 11am</td>

<tr>
<td></td>
<td><b>Angus Leigh</b><br>
Email: <i>angus.leigh@cs.mcgill.ca</i><br>
Office: McConnell 111<br>
Office hours: Wednesday, 11am</td>
</tr>


<tr>
<td><u>Class web page:</u><br>&nbsp;</td><td><a href="http://www.cs.mcgill.ca/~jpineau/comp598">http://www.cs.mcgill.ca/~jpineau/comp598</a>
</tr>


</table></center>

<p><h3><u>Course Description</u></h3>
<p>

The course will cover selected topics and new developments in Data mining and Machine learning, with a particular emphasis on good methods and practices for effective deployment of real systems.  We will study commonly used algorithms and techniques, including clustering, neural networks, support vector machines, decision trees.  We will also discuss methods to address practical issues such as feature selection and dimensionality reduction, error estimation and empirical validation, algorithm design and parallelization, and handling of large datasets.

<!-- The course will be designed partly as a "flipped classroom" model, whereby students are expected to watch short videos and complete reading on their own time.  Classroom time is to be used for active discussion, problem-solving, student presentations, and so on. -->

<p><h3><u>Course content (subject to minor changes):</u></h3>
<ol>
<li> Linear regression. Linear classification.
<li> Performance evaluation, overfitting, cross-validation, bias-variance analysis, error estimation.
			  <li> Naive Bayes.
<li> Decision trees.  Regression trees and ensemble methods.
<li> Cost-sensitive learning.
<li> Support vector machines.
<li> Artificial neural networks. Deep learning.
<li> Feature selection. Dimensionality reduction. Regularization.
<li> Online / streaming data.
<li> Data structures and Map-Reduce.
<li> Unsupervised learning and clustering. Semi-supervised learning.
<li> Applications.
</ol>

<p>
<p><h3><u>Reference Materials</u></h3>
				   
There is no required textbook. Lecture notes and references will be available from the course web page. The following texts can also be very useful:
<br>
<ol>
<li>Trevor Hastie, Robert Tibshirani and Jerome Friedman. <i>The Elements of Statistical Learning: Data Mining, Inference, and Prediction, 2nd Edition</i>. Springer. 2009. Available <a href="http://www-stat.stanford.edu/~tibs/ElemStatLearn/">free online</a>.
<li>Christopher Bishop. <i>Pattern Recognition and Machine Learning</i>. Springer. 2007.
<li>Kevin Murphy. <i>Machine Learning: A Probabilistic Perspective</i>. The MIT Press. 2012.
<li>David MacKay. <i>Information Theory, Inference and Learning Algorithms</i>. Cambridge University Press. 2003.
<li>Richard Duda, Peter Hard and David Stork. <i>Pattern Classification. 2nd Edition</i>. Wiley & Sons. 2001.
</ol><p>

<p><h3><u>Prerequisites / Anterequesites</u></h3>

Basic knowledge of a programming language is required. Basic knowledge of probabilities/statistics, calculus and linear algebra is required. Example courses at McGill providing sufficient background in probability are MATH-323 or ECSE-305. Some AI background is recommended, as provided, for instance by COMP-424 or ECSE-526, but not required. If you have doubts regarding your background, please contact me to discuss it.
<p>
Students who took COMP-652 in 2012 or before CANNOT take COMP-598. Starting in Fall 2013, COMP-598 and COMP-652 were designed to avoid significant overlap; you can take either or both.
<p>
<b>The courses is intended for hard-working, technically skilled, highly motivated students.  Participants will be expected to display initiative, creativity, scientific rigour, critical thinking, and good communication skills.</b>


<p><h3><u>Evaluation Criteria</u></h3>

The class grade will be based on the following components:
<ul>
<li>Weekly quizzes and exercises - 5%
<li>One in-class written midterm examination - 35%
<li>Four data analysis case studies + peer reviews - 60%
				</ul>

<p>The weekly exercises will consist of quizzes (in class) or practical work (take-home) designed to develop basic understanding of the course material as we progress through the topics. These are designed to provide some practice for the midterm.</p>

<p> The midterm is designed to assess in-depth understanding of fundamental methods and algorithms. It will be scheduled towards the later end of the semester (mid-November).  There is no final exam.

<p>The data analysis case studies will require reading, writing, programming and experiments to gain hands-on experience with the application of recent machine learning methods, including concepts covered in the lectures, and concepts drawn from the literature.  Students will be responsible for characterizing the problem, developing methods of analysis, and presenting the results of their work.  Some case studies may be individual, most will be done in groups (usually of 3 or less).

<p>We will use a peer-review system to evaluate the data analysis case studies.  Each student will be asked to read and evaluate submissions of their colleagues.  The emphasis will be placed on providing constructive feedback on the methodology and presentation.


<p><h3><u>Evaluation Policy</u></h3>

All course work should be submitted online (details to be given in class), by 11:59pm, on the assigned due date. Late work will be automatically subject to a 30% penalty, and can be submitted up to 1 week after the deadline.
<p>
No make-up midterm will be given.</b>
<p>
<b><u>Some of the course work will be individual, other components can be completed in groups.  It is the responsibility of each student to understand the policy for each work, and ask questions of the instructor if this is not clear.</u></b> It is also the responsibility of each student to carefully acknowledge all sources (papers, code, books, websites, individual communications) using appropriate referencing style when submitting work.</b>
<p>
We will use automated systems to detect possible cases of text or software plagiarism.  Cases that warrant further investigation will be referred to the university disciplinary officers.  Students who have concerns about how to properly use and acknowledge third-party software should consult the course instructor or TAs.
<p>
McGill University values academic integrity.  Therefore all students must understand
the meaning and consequences of cheating, plagiarism and other academic offences
under the Code of Student Conduct and Disciplinary Procedures (see
www.mcgill.ca/students/srr/honest/<http://www.mcgill.ca/students/srr/honest/> ) for
more information).
<p>
In accord with McGill University's Charter of Students' Rights, students in this
course have the right to submit in English or in French any written work that is to
be graded.
<p>
In the event of extraordinary circumstances beyond the University's control, the content and/or evaluation scheme in this course is subject to change.

</body>

</html>
